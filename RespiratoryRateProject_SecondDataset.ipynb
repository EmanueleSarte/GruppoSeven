{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> RESPIRATORY RATE ESTIMATION\n",
    " \n",
    " **08/02/2023**   \n",
    "    \n",
    " **Group 7:** **Giovanni Zago**, **Enrico Lupi**, **Emanuele Sarte**, **Alessio Saccomani** \n",
    " \n",
    "   The aim of this project is to estimate the Respiratory Rate (RR) by Seismocardiography(SCG), a technique where the detector is positioned above sternum, and Ballistocardiography (BCG), in which there is no contact between the sensor and the body: in this study the sensor was placed on the subject chest directly on a sweater). The measurements were taken using the detector MuSe (Multi-sensor miniaturized, low-power, wireless Inertial Measurement Unit), provided by 221e (https://www.221e.com). An IMU is a combination of an accelerometer and a gyroscope sensor, capable of detecting movements and measuring their intensity in terms of acceleration and rotational speeds. Sometimes, like in this case, a magnetometer is also included. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> \n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"Forwarding\" src=\"https://www.researchgate.net/profile/Niccolo-Mora/publication/332138445/figure/fig2/AS:743069842407425@1554173064707/Positioning-of-IMU-sensor-and-ECG-electrodes-The-IMU-is-placed-over-the-subjects.ppm\" width=\"320\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\"></em>\n",
    "  </p> \n",
    "</td>\n",
    "<td> \n",
    "  <p align=\"center\">\n",
    "    <img alt=\"Routing\" src=\"https://www.221e.com/wp-content/uploads/2022/10/221e-Muse1.jpg\" width=\"515\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\"></em>\n",
    "  </p> \n",
    "</td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and First Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary libraries for the analysis (pandas, numpy, matplotlib, scipy, ecc.). \n",
    "\n",
    "We then load the datafile 'center_sternum.txt' as a pandas dataframe. For the following analysis we decide to take into account the linear acceleration (in mg), the angular velocity (in degrees per second) and the magnetic field (in mG) in all three directions; the quaternions are not considered, instead, so they are dropped. Afterwards, we calibrate the measurements using the information in the file README_1.txt and we add to the dataset the absolute time at which every measurement is taken: as the data collection frequency is 200 Hz, each measurement is taken every 5 ms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fftpack\n",
    "from scipy import fft\n",
    "from scipy import signal\n",
    "from scipy import optimize\n",
    "from scipy import linalg\n",
    "import seaborn as sns\n",
    "import pywt\n",
    "sns.set_theme(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"center_sternum.txt\", \"1_Stave_supine_static.txt\", \"2_Mattress_supine.txt\", \n",
    "             \"3_Subject_sitting_chair.txt\", \"4_Chest_sweater.txt\", \"5_Under_chair.txt\"]\n",
    "data_cuts = [(6,70), (16, 80), (14, 112), (5, 65), (5, 145), (8, 90)]\n",
    "\n",
    "FILE_CHOSEN = 4\n",
    "\n",
    "T1_CUT = data_cuts[FILE_CHOSEN][0]\n",
    "T2_CUT = data_cuts[FILE_CHOSEN][1]\n",
    "file_name = filenames[FILE_CHOSEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log Freq</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Abs Time</th>\n",
       "      <th>AccX</th>\n",
       "      <th>AccY</th>\n",
       "      <th>AccZ</th>\n",
       "      <th>GyroX</th>\n",
       "      <th>GyroY</th>\n",
       "      <th>GyroZ</th>\n",
       "      <th>MagnX</th>\n",
       "      <th>MagnY</th>\n",
       "      <th>MagnZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1555414552</td>\n",
       "      <td>0.00</td>\n",
       "      <td>687.836</td>\n",
       "      <td>380.823</td>\n",
       "      <td>580.354</td>\n",
       "      <td>-7.926829</td>\n",
       "      <td>8.048780</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>-592</td>\n",
       "      <td>122</td>\n",
       "      <td>-113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1555414552</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-812.703</td>\n",
       "      <td>-108.946</td>\n",
       "      <td>726.876</td>\n",
       "      <td>-11.707320</td>\n",
       "      <td>-81.829270</td>\n",
       "      <td>8.780488</td>\n",
       "      <td>125</td>\n",
       "      <td>60</td>\n",
       "      <td>-128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1555414552</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-812.520</td>\n",
       "      <td>-108.824</td>\n",
       "      <td>733.952</td>\n",
       "      <td>-37.073170</td>\n",
       "      <td>-145.487800</td>\n",
       "      <td>14.756100</td>\n",
       "      <td>123</td>\n",
       "      <td>59</td>\n",
       "      <td>-136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>1555414552</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-787.144</td>\n",
       "      <td>-45.628</td>\n",
       "      <td>616.954</td>\n",
       "      <td>-56.341460</td>\n",
       "      <td>-174.634200</td>\n",
       "      <td>23.048780</td>\n",
       "      <td>118</td>\n",
       "      <td>58</td>\n",
       "      <td>-145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>1555414552</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-800.259</td>\n",
       "      <td>-137.433</td>\n",
       "      <td>411.689</td>\n",
       "      <td>-1.097561</td>\n",
       "      <td>37.073170</td>\n",
       "      <td>1.341463</td>\n",
       "      <td>113</td>\n",
       "      <td>57</td>\n",
       "      <td>-157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14933</th>\n",
       "      <td>100</td>\n",
       "      <td>1555415471</td>\n",
       "      <td>149.33</td>\n",
       "      <td>-890.722</td>\n",
       "      <td>-81.008</td>\n",
       "      <td>446.764</td>\n",
       "      <td>-2.682927</td>\n",
       "      <td>2.926829</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>144</td>\n",
       "      <td>47</td>\n",
       "      <td>-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14934</th>\n",
       "      <td>100</td>\n",
       "      <td>1555415471</td>\n",
       "      <td>149.34</td>\n",
       "      <td>-885.964</td>\n",
       "      <td>-76.006</td>\n",
       "      <td>459.025</td>\n",
       "      <td>-3.902439</td>\n",
       "      <td>3.292683</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>146</td>\n",
       "      <td>45</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14935</th>\n",
       "      <td>100</td>\n",
       "      <td>1555415471</td>\n",
       "      <td>149.35</td>\n",
       "      <td>-879.681</td>\n",
       "      <td>-77.714</td>\n",
       "      <td>475.068</td>\n",
       "      <td>-3.048780</td>\n",
       "      <td>2.804878</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>144</td>\n",
       "      <td>46</td>\n",
       "      <td>-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14936</th>\n",
       "      <td>100</td>\n",
       "      <td>1555415471</td>\n",
       "      <td>149.36</td>\n",
       "      <td>-894.992</td>\n",
       "      <td>-76.311</td>\n",
       "      <td>502.701</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>1.463415</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>144</td>\n",
       "      <td>45</td>\n",
       "      <td>-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14937</th>\n",
       "      <td>100</td>\n",
       "      <td>1555415471</td>\n",
       "      <td>149.37</td>\n",
       "      <td>-889.319</td>\n",
       "      <td>-90.951</td>\n",
       "      <td>471.835</td>\n",
       "      <td>3.536585</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>144</td>\n",
       "      <td>45</td>\n",
       "      <td>-53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14938 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Log Freq   Timestamp  Abs Time     AccX     AccY     AccZ      GyroX  \\\n",
       "0           100  1555414552      0.00  687.836  380.823  580.354  -7.926829   \n",
       "1           100  1555414552      0.01 -812.703 -108.946  726.876 -11.707320   \n",
       "2           100  1555414552      0.02 -812.520 -108.824  733.952 -37.073170   \n",
       "3           100  1555414552      0.03 -787.144  -45.628  616.954 -56.341460   \n",
       "4           100  1555414552      0.04 -800.259 -137.433  411.689  -1.097561   \n",
       "...         ...         ...       ...      ...      ...      ...        ...   \n",
       "14933       100  1555415471    149.33 -890.722  -81.008  446.764  -2.682927   \n",
       "14934       100  1555415471    149.34 -885.964  -76.006  459.025  -3.902439   \n",
       "14935       100  1555415471    149.35 -879.681  -77.714  475.068  -3.048780   \n",
       "14936       100  1555415471    149.36 -894.992  -76.311  502.701   0.121951   \n",
       "14937       100  1555415471    149.37 -889.319  -90.951  471.835   3.536585   \n",
       "\n",
       "            GyroY      GyroZ  MagnX  MagnY  MagnZ  \n",
       "0        8.048780   0.975610   -592    122   -113  \n",
       "1      -81.829270   8.780488    125     60   -128  \n",
       "2     -145.487800  14.756100    123     59   -136  \n",
       "3     -174.634200  23.048780    118     58   -145  \n",
       "4       37.073170   1.341463    113     57   -157  \n",
       "...           ...        ...    ...    ...    ...  \n",
       "14933    2.926829   0.365854    144     47    -50  \n",
       "14934    3.292683   0.365854    146     45    -51  \n",
       "14935    2.804878   0.365854    144     46    -54  \n",
       "14936    1.463415   0.609756    144     45    -53  \n",
       "14937    0.853659   0.609756    144     45    -53  \n",
       "\n",
       "[14938 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(file_name, sep=\"\\t\")\n",
    "\n",
    "# We drop the columns we are not going to use\n",
    "raw_data = raw_data.drop([\"Log Mode\", \"qw\", \"qi\", \"qj\", \"qk\"], axis=1)\n",
    "\n",
    "# We look that the data collection frequency is the same for all the dataset\n",
    "if len(raw_data[\"Log Freq\"].unique()) != 1:\n",
    "    print(\"There is more than one frequency\")\n",
    "    exit(1)\n",
    "\n",
    "# We select the frequency\n",
    "ACQ_FREQ = raw_data.loc[0, \"Log Freq\"]\n",
    "\n",
    "# We create a column with the absolute time by multiplying 1/freq by integers\n",
    "raw_data.insert(2, \"Abs Time\", np.arange(0, len(raw_data)) * (1 / ACQ_FREQ), allow_duplicates=False)\n",
    "\n",
    "display(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log Freq</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Abs Time</th>\n",
       "      <th>AccX</th>\n",
       "      <th>AccY</th>\n",
       "      <th>AccZ</th>\n",
       "      <th>GyroX</th>\n",
       "      <th>GyroY</th>\n",
       "      <th>GyroZ</th>\n",
       "      <th>MagnX</th>\n",
       "      <th>MagnY</th>\n",
       "      <th>MagnZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1555414552</td>\n",
       "      <td>0.00</td>\n",
       "      <td>696.048334</td>\n",
       "      <td>360.120513</td>\n",
       "      <td>655.516657</td>\n",
       "      <td>-10.731228</td>\n",
       "      <td>9.841885</td>\n",
       "      <td>1.316781</td>\n",
       "      <td>-755.923364</td>\n",
       "      <td>224.279578</td>\n",
       "      <td>526.424080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1555414552</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-808.374494</td>\n",
       "      <td>-131.333370</td>\n",
       "      <td>800.705773</td>\n",
       "      <td>-14.511719</td>\n",
       "      <td>-80.036165</td>\n",
       "      <td>9.121659</td>\n",
       "      <td>-26.329221</td>\n",
       "      <td>127.950721</td>\n",
       "      <td>510.420932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1555414552</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-808.160179</td>\n",
       "      <td>-131.221239</td>\n",
       "      <td>807.998826</td>\n",
       "      <td>-39.877569</td>\n",
       "      <td>-143.694695</td>\n",
       "      <td>15.097271</td>\n",
       "      <td>-28.293915</td>\n",
       "      <td>126.974690</td>\n",
       "      <td>502.865171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>1555414552</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-783.211118</td>\n",
       "      <td>-67.681388</td>\n",
       "      <td>687.441203</td>\n",
       "      <td>-59.145859</td>\n",
       "      <td>-172.841095</td>\n",
       "      <td>23.389951</td>\n",
       "      <td>-33.297058</td>\n",
       "      <td>126.132302</td>\n",
       "      <td>494.371088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>1555414552</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-797.266105</td>\n",
       "      <td>-159.441850</td>\n",
       "      <td>475.973393</td>\n",
       "      <td>-3.901960</td>\n",
       "      <td>38.866275</td>\n",
       "      <td>1.682634</td>\n",
       "      <td>-38.294616</td>\n",
       "      <td>125.265247</td>\n",
       "      <td>483.045282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14933</th>\n",
       "      <td>100</td>\n",
       "      <td>1555415471</td>\n",
       "      <td>149.33</td>\n",
       "      <td>-887.841091</td>\n",
       "      <td>-102.921591</td>\n",
       "      <td>511.646512</td>\n",
       "      <td>-5.487326</td>\n",
       "      <td>4.719934</td>\n",
       "      <td>0.707024</td>\n",
       "      <td>-6.604362</td>\n",
       "      <td>114.630747</td>\n",
       "      <td>583.903476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14934</th>\n",
       "      <td>100</td>\n",
       "      <td>1555415471</td>\n",
       "      <td>149.34</td>\n",
       "      <td>-883.015136</td>\n",
       "      <td>-97.923207</td>\n",
       "      <td>524.295993</td>\n",
       "      <td>-6.706838</td>\n",
       "      <td>5.085788</td>\n",
       "      <td>0.707024</td>\n",
       "      <td>-4.481049</td>\n",
       "      <td>112.518283</td>\n",
       "      <td>582.939401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14935</th>\n",
       "      <td>100</td>\n",
       "      <td>1555415471</td>\n",
       "      <td>149.35</td>\n",
       "      <td>-876.643826</td>\n",
       "      <td>-99.658473</td>\n",
       "      <td>540.859477</td>\n",
       "      <td>-5.853179</td>\n",
       "      <td>4.597983</td>\n",
       "      <td>0.707024</td>\n",
       "      <td>-6.549627</td>\n",
       "      <td>113.593026</td>\n",
       "      <td>580.119623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14936</th>\n",
       "      <td>100</td>\n",
       "      <td>1555415471</td>\n",
       "      <td>149.36</td>\n",
       "      <td>-891.880238</td>\n",
       "      <td>-98.292933</td>\n",
       "      <td>569.269111</td>\n",
       "      <td>-2.682448</td>\n",
       "      <td>3.256520</td>\n",
       "      <td>0.950927</td>\n",
       "      <td>-6.504200</td>\n",
       "      <td>112.596416</td>\n",
       "      <td>581.055309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14937</th>\n",
       "      <td>100</td>\n",
       "      <td>1555415471</td>\n",
       "      <td>149.37</td>\n",
       "      <td>-886.325866</td>\n",
       "      <td>-112.927826</td>\n",
       "      <td>537.504822</td>\n",
       "      <td>0.732186</td>\n",
       "      <td>2.646764</td>\n",
       "      <td>0.950927</td>\n",
       "      <td>-6.504200</td>\n",
       "      <td>112.596416</td>\n",
       "      <td>581.055309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14938 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Log Freq   Timestamp  Abs Time        AccX        AccY        AccZ  \\\n",
       "0           100  1555414552      0.00  696.048334  360.120513  655.516657   \n",
       "1           100  1555414552      0.01 -808.374494 -131.333370  800.705773   \n",
       "2           100  1555414552      0.02 -808.160179 -131.221239  807.998826   \n",
       "3           100  1555414552      0.03 -783.211118  -67.681388  687.441203   \n",
       "4           100  1555414552      0.04 -797.266105 -159.441850  475.973393   \n",
       "...         ...         ...       ...         ...         ...         ...   \n",
       "14933       100  1555415471    149.33 -887.841091 -102.921591  511.646512   \n",
       "14934       100  1555415471    149.34 -883.015136  -97.923207  524.295993   \n",
       "14935       100  1555415471    149.35 -876.643826  -99.658473  540.859477   \n",
       "14936       100  1555415471    149.36 -891.880238  -98.292933  569.269111   \n",
       "14937       100  1555415471    149.37 -886.325866 -112.927826  537.504822   \n",
       "\n",
       "           GyroX       GyroY      GyroZ       MagnX       MagnY       MagnZ  \n",
       "0     -10.731228    9.841885   1.316781 -755.923364  224.279578  526.424080  \n",
       "1     -14.511719  -80.036165   9.121659  -26.329221  127.950721  510.420932  \n",
       "2     -39.877569 -143.694695  15.097271  -28.293915  126.974690  502.865171  \n",
       "3     -59.145859 -172.841095  23.389951  -33.297058  126.132302  494.371088  \n",
       "4      -3.901960   38.866275   1.682634  -38.294616  125.265247  483.045282  \n",
       "...          ...         ...        ...         ...         ...         ...  \n",
       "14933  -5.487326    4.719934   0.707024   -6.604362  114.630747  583.903476  \n",
       "14934  -6.706838    5.085788   0.707024   -4.481049  112.518283  582.939401  \n",
       "14935  -5.853179    4.597983   0.707024   -6.549627  113.593026  580.119623  \n",
       "14936  -2.682448    3.256520   0.950927   -6.504200  112.596416  581.055309  \n",
       "14937   0.732186    2.646764   0.950927   -6.504200  112.596416  581.055309  \n",
       "\n",
       "[14938 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#calibrate the dataset\n",
    "offset_gyro = np.array([-2.242224, 2.963463, -0.718397])\n",
    "\n",
    "calibration_acc = np.array([[1.000966,     -0.002326418,-0.0006995499],\n",
    "                            [-0.002326379,  0.9787045,  -0.001540918],\n",
    "                            [-0.0006995811,-0.001540928, 1.00403]])\n",
    "offset_acc = np.array([-3.929942, -13.74679, 60.67546])\n",
    "\n",
    "calibration_magn = np.array([[0.9192851, -0.02325168, 0.003480837],\n",
    "                             [-0.02325175, 0.914876, 0.004257396],\n",
    "                             [0.003481006, 0.004257583, 0.8748001]])\n",
    "offset_magn = np.array([-95.67974, -244.9142, 17.71132])\n",
    "\n",
    "if file_name != \"center_sternum.txt\":\n",
    "    offset_gyro = np.array([-2.804399, 1.793105, 0.3411708])\n",
    "\n",
    "    calibration_acc = np.array([[1.002982,    9.415505E-05, 0.004346743],\n",
    "                                [9.04459E-05, 1.002731,    -0.001444198],\n",
    "                                [0.004346536,-0.001444751,  1.030587]])\n",
    "    offset_acc = np.array([3.602701, -20.96658, 54.97186])\n",
    "\n",
    "    calibration_magn = np.array([[1.013437,    -0.04728858,  -0.001861475],\n",
    "                                 [-0.04728862,  1.004832,    0.008222118],\n",
    "                                 [-0.001861605, 0.008221965, 0.9439077]])\n",
    "    offset_magn = np.array([-150.4098, 74.62431, 630.9805])\n",
    "\n",
    "raw_data[['AccX', 'AccY', 'AccZ']] = np.dot(raw_data[['AccX', 'AccY', 'AccZ']], calibration_acc.T) + offset_acc.T\n",
    "raw_data[['GyroX', 'GyroY', 'GyroZ']] = raw_data[['GyroX', 'GyroY', 'GyroZ']] + offset_gyro.T\n",
    "raw_data[['MagnX', 'MagnY', 'MagnZ']] = np.dot(raw_data[['MagnX', 'MagnY', 'MagnZ']], calibration_magn.T) + offset_magn.T\n",
    "\n",
    "display(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "\n",
    "We now plot the accelerations, the angular velocity and the magnetic field components as a function of time in order to look at their general trend and to select a proper time window to conduct the analysis in. This is necessary as signals are very disturbed at the beginning and end of the data taking, probably due to sudden movements of the test subject: they are ususally used to coordinate the data taking across various devices, but they mud the data and need of course to be eliminated. \n",
    "\n",
    "From 6 to 70 seconds all features have a regular behaviour and thus we select this to be the time window to be used in the rest of the project. In the plots this time window is highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator, FuncFormatter\n",
    "\n",
    "labels = [\"GyroX\", \"GyroY\", \"GyroZ\", \"AccX\", \"AccY\", \"AccZ\", \"MagnX\", \"MagnY\", \"MagnZ\"]\n",
    "unit = [\"[deg/s]\", \"[mg]\", \"[mG]\"]\n",
    "Nvar = len(labels)\n",
    "   \n",
    "IT1_CUT = round(T1_CUT * ACQ_FREQ)\n",
    "IT2_CUT = round(T2_CUT * ACQ_FREQ) + 1\n",
    "\n",
    "plt.figure(figsize=(18, 4 * (Nvar // 3)))\n",
    "for i in range(Nvar // 3):\n",
    "    ax = plt.subplot(Nvar // 3, 1, i + 1)\n",
    "    plt.plot(raw_data[\"Abs Time\"], raw_data[labels[i * 3]],     label=labels[i * 3])\n",
    "    plt.plot(raw_data[\"Abs Time\"], raw_data[labels[i * 3 + 1]], label=labels[i * 3 + 1])\n",
    "    plt.plot(raw_data[\"Abs Time\"], raw_data[labels[i * 3 + 2]], label=labels[i * 3 + 2])\n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.vlines(x=raw_data.loc[IT1_CUT, \"Abs Time\"], ymin=ymin, ymax=ymax, colors=\"black\")\n",
    "    plt.vlines(x=raw_data.loc[IT2_CUT, \"Abs Time\"], ymin=ymin, ymax=ymax, colors=\"black\")\n",
    "\n",
    "    ax.fill_between(raw_data.loc[IT1_CUT: IT2_CUT, \"Abs Time\"], ymin, ymax, color='C0', alpha=0.25)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(10))\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Magnitude \"+unit[i])\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "raw_data_cut = raw_data.loc[IT1_CUT: IT2_CUT - 1, :]\n",
    "display(raw_data_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis\n",
    "\n",
    "We calculate the mean, standard deviation, minimum, 25th, 50th, 75th percentiles and maximum for all features (in the selected time window); data is then normalized. \n",
    "For the accelerations and the angular velocities the 25th and 75th percentiles are nearly symmetric, so the variables change quite regularly. \n",
    "\n",
    "Afterwards, normalized data is plotted in a 9x9 grid in order to highlight possible correlations: however, no significant correlation has been noticed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_cut.drop([\"Log Freq\", \"Timestamp\", \"Abs Time\"], axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_std = (raw_data_cut[labels] - np.mean(raw_data_cut[labels], axis=0)) / np.std(raw_data_cut[labels], axis=0)\n",
    "data_std.insert(0, \"Abs Time\", raw_data_cut[\"Abs Time\"])\n",
    "data_std.set_index(np.arange(0, len(data_std)), inplace=True)\n",
    "display(data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_std[labels]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "In order to reduce the dimensionality of the dataset we perform a **PCA**, keeping only 6 out of the total 9 principal components so as to maintain at least 85% of the total variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avls, avts = linalg.eig(np.cov(data_std[labels].T))\n",
    "sort_perm = np.flip(np.argsort(avls))\n",
    "\n",
    "avls = np.real_if_close(avls[sort_perm])\n",
    "avts = avts[:, sort_perm]\n",
    "\n",
    "var_ratios = avls / np.sum(avls)\n",
    "print('Eigenvalues (sorted):\\n', np.round(avls, 4)) \n",
    "print('Variability ratios:\\n', np.round(var_ratios * 100, 2))\n",
    "print(\"Eigenvector:\")\n",
    "display(pd.DataFrame(avts, columns=[f\"Avt {i+1}\" for i in range(len(avls))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_LABELS = [f\"PC{i+1}\" for i in range(len(avls))]\n",
    "data_rot = pd.DataFrame(data=np.dot(avts.T, data_std[labels].T).T, columns=PCA_LABELS)\n",
    "\n",
    "perc_thr = .85\n",
    "N_PCA = np.argmax(np.cumsum(var_ratios) >= perc_thr) + 1\n",
    "\n",
    "print(f'To keep {int(perc_thr * 100)}% of variability in our dataset we need {N_PCA} out of the {len(var_ratios)} principal components')\n",
    "\n",
    "display(data_rot)\n",
    "\n",
    "PCA_LABELS = PCA_LABELS[:N_PCA]\n",
    "data_pca = data_rot[data_rot.columns[:N_PCA]]\n",
    "data_pca.insert(0, \"Abs Time\", data_std[\"Abs Time\"])\n",
    "display(data_pca)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Analysis\n",
    "\n",
    "We then perform a **Fourier analysis** using the scipy fft library in order to extrapolate the principal frequencies of the data: we expect to see a peak in the range [0.1, 0.3] Hz, the average respiratory rate in an adult.\n",
    "\n",
    "We first plot as an example the whole power spectrum of PC3: we can clearly see a **peak around 0.2 Hz** due to respiration and one around 1.1 Hz corresponding to the heart rate, while the peaks at high frequencies are due to noise. As we are only interested in the respiratory rate, all following plots will be focused only in the [0, 0.9] Hz range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fft = fft.fftshift(fft.fft(data_pca[PCA_LABELS], axis=0))\n",
    "sample_freq = fft.fftshift(fft.fftfreq(len(data_pca), d=1/ACQ_FREQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.plot(sample_freq, np.abs(sig_fft[:, 2]), label=\"Fourier Transform of \" + PCA_LABELS[2])\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_xticks(np.arange(0, 10, 0.5))\n",
    "plt.xlabel(\"Freq [Hz]\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5 * N_PCA))\n",
    "for i in range(N_PCA):\n",
    "    ax = plt.subplot(N_PCA, 1, i+1)\n",
    "    plt.plot(sample_freq, np.abs(sig_fft[:, i]), label=\"Frequency Spectrum \" + PCA_LABELS[i])\n",
    "    ax.set_xlim(0, 0.9)\n",
    "    plt.xticks(np.arange(0, 1, 0.05))\n",
    "        \n",
    "    plt.xlabel(\"Freq [Hz]\")\n",
    "    plt.ylabel(\"Power\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fft_w = np.zeros_like(sig_fft)\n",
    "for i in range(N_PCA):\n",
    "    sig_fft_w[:, i] = sig_fft[:, i]*var_ratios[i] \n",
    "total_FFT = np.sum(np.abs(sig_fft_w), axis=1)\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.plot(sample_freq, total_FFT, label=\"Frequency Spectrum of Weighted Sum of PCs\")\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.xticks(np.arange(0, 0.9, 0.05))\n",
    "plt.xlim(left=0, right=0.9)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter\n",
    "\n",
    "We now apply a filter using a **wavelet transform** in order to extrapolate only the components of the signal at the desired frequencies.\n",
    "\n",
    "Wavelet transform is a powerful alternative to Fourier transform, able not only to the frequency information of the dataset but also at which moment a particular frequency is present. In this project we used a dyadic tree-level wavelet decomposition via the wavelet **sym5**, as it is smooth and allows for a high level of decomposition. In the first level, the signal is split into low- and high-frequency components, that respectively provide the coarser part and the detailed information of the original signal and are thus termed as the approximation and the detail; this first low-frequency subband component is then downsampled by a factor of 2 and again decomposed into low- and high-frequency subbands. This process can be repeated to J levels as desired: in this project we stopped at level 10. The frequency range covered by AJ is $0$ to $f_{s}/2^{J+1}$ Hz and that for Dj is $f_{s}/2^{j+1}$ to $f_{s}/2^{j}$ Hz ($1\\le j \\le J$), where $f_{s}$ represents the sampling frequency (in unit Hz) of the original signal, so 200 Hz in our case. [Source](https://doi.org/10.1016/j.bspc.2019.101779) \n",
    "\n",
    "For this project we want to filter the high frquencies components due to heart beats and noise, and also very low, near-zero frequencies: we will thus reconstruct the time signal using only the coefficients for **D10** and **D9** which correspond to a range of [0.098, 0.39] Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter signal using wavelets\n",
    "\n",
    "lvl = 10\n",
    "if file_name != \"center_sternum.txt\":\n",
    "    lvl = 9\n",
    "\n",
    "coeffs = pywt.wavedec(data_pca[PCA_LABELS], \"sym5\", level=lvl, axis=0)\n",
    "#set coefficients related to undesired freuqncies to zero \n",
    "coeffs[0] = np.zeros_like(coeffs[0]) #set A10 to zero\n",
    "for i in range(3, lvl + 1):\n",
    "    coeffs[i] = np.zeros_like(coeffs[i]) #set Dj to zero with j from 8 to 1\n",
    "\n",
    "#reconstruct time signal \n",
    "filtered_sig = pywt.waverec(coeffs, \"sym5\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot recostructed time signal\n",
    "fig, axs = plt.subplots(nrows=N_PCA, ncols=1, figsize=(18, N_PCA*5))\n",
    "\n",
    "for i in range(N_PCA):\n",
    "    axs[i].plot(data_pca[\"Abs Time\"], filtered_sig[:-1, i], label=(\"Wavelet Filtered \"+PCA_LABELS[i]))\n",
    "        \n",
    "    axs[i].set_xlabel(\"Time [s]\")\n",
    "    axs[i].set_ylabel(\"Magnitude\") \n",
    "    axs[i].legend(loc=\"best\")\n",
    "    axs[i].xaxis.set_major_locator(plt.MultipleLocator(5))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now quickly repeat a Fourier analysis in order to show that indeed only the desired frequencies are kept after the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fft_wt = fft.fftshift(fft.fft(filtered_sig[:-1, :], axis=0))\n",
    "sample_freq = fft.fftshift(fft.fftfreq(len(data_pca), d=1/ACQ_FREQ))\n",
    "\n",
    "plt.figure(figsize=(18, 5 * N_PCA))\n",
    "for i in range(N_PCA):\n",
    "    ax = plt.subplot(N_PCA, 1, i+1)\n",
    "    plt.plot(sample_freq, np.abs(sig_fft[:, i]), label=PCA_LABELS[i])\n",
    "    plt.plot(sample_freq, np.abs(sig_fft_wt[:, i]),\n",
    "             label=\"Wavelet Filtered \" + PCA_LABELS[i])\n",
    "    ax.set_xlim(0, 0.9)\n",
    "    plt.xticks(np.arange(0, 1, 0.05))\n",
    "        \n",
    "    plt.xlabel(\"Freq [Hz]\")\n",
    "    plt.ylabel(\"Power\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having filtered our signals we are ready to extract the **Respiratory Rate (RR)** and the **Respiratory Rate Variability (RRV)** from them. The idea is to spot the peaks of our signals, in order to compute the difference of their corresponding consecutive x-coordinate: this allows us to collect a sample of periods $T_i$ that can be further elaborated to estimate RR and RRV. To do so we start by naively using the find_peaks function of Scipy on each of our filtered PC signals. However, find_peaks, if used without appropriate parameters, returns raw peaks that do not reflect properly the periodicity of the signals, as it will be evident from the example plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sig=filtered_sig.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = []\n",
    "valleys = []\n",
    "for i in range(len(filtered_sig)):\n",
    "    temp_signal = filtered_sig[i][:-1]\n",
    "    temp_peaks, _ = signal.find_peaks(temp_signal)\n",
    "    temp_valleys, _ = signal.find_peaks(-temp_signal)\n",
    "    peaks.append(temp_signal[temp_peaks])\n",
    "    peaks.append(data_std['Abs Time'].values[temp_peaks])\n",
    "    valleys.append(temp_signal[temp_valleys])\n",
    "    valleys.append(data_std['Abs Time'].values[temp_valleys])\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(18, 5 ))\n",
    "    \n",
    "ax.plot(data_std['Abs Time'], filtered_sig[1][:-1], label=\"Wavelet Filtered \"+PCA_LABELS[1])\n",
    "ax.plot(peaks[1 * 2 + 1], peaks[1 * 2], 'x', label=\"Peaks\", markersize=10, markeredgewidth=3)\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "ax.set_ylabel(\"Magnitude\")\n",
    "ax.legend(loc=\"best\")\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(5))\n",
    "\n",
    "'''\n",
    "fig, ax = plt.subplots(len(filtered_sig), 1, figsize=(18, 5 * N_PCA))\n",
    "for i in range(len(peaks) // 2):    \n",
    "    ax[i].plot(data_std['Abs Time'], filtered_sig[i][:-1], label=\"Wavelet Filtered \"+PCA_LABELS[i])\n",
    "    ax[i].plot(peaks[i * 2 + 1], peaks[i * 2], 'x', label=\"Peaks\", markersize=10, markeredgewidth=3)\n",
    "    ax[i].set_xlabel(\"Time [s]\")\n",
    "    ax[i].set_ylabel(\"Magnitude\")\n",
    "    ax[i].legend(loc=\"best\")\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving Peak Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve the detection of the peaks we run the code again, paying attention to properly setting the parameters *height* and *distance* of the function find peaks. The former sets an height level that each sample must reach in order to be potentially recognized as a peak, and it has been set equal to the 70% of the mean y-difference between maxima and the following minima. The latter sets a minimum sample distance that needs to occur between subsequent peaks, and has been set equal to the 70% of the mean peak distance. In both cases we have set the 70% of the two quantities so as to preserve the variability of the $T_i$, otherwise small $T_i$ values would have been excessively penalized with respect to larger ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_peak_dist = []\n",
    "for i in range(1, len(peaks), 2):    \n",
    "    avg_peak_dist.append(len(data_std['Abs Time']) / len(peaks[i]))\n",
    "\n",
    "sign_amp = []\n",
    "for i in range(1, len(peaks), 2):\n",
    "    temp_sign_amp = []    \n",
    "    for j in range(np.min([len(peaks[i]), len(valleys[i])])):\n",
    "        temp_peaks = np.array(peaks[i-1])\n",
    "        temp_valleys = np.array(valleys[i-1])\n",
    "        temp_sign_amp.append(0.5*np.abs(temp_peaks[j] + temp_valleys[j]))\n",
    "    sign_amp.append(temp_sign_amp)\n",
    "\n",
    "avg_sign_amp = np.empty(shape=(len(filtered_sig)))\n",
    "for i,x  in enumerate(sign_amp):\n",
    "    avg_sign_amp[i] = np.mean(x)\n",
    "\n",
    "height_perc = .6\n",
    "distance_perc = .7\n",
    "peaks_refined = []\n",
    "valleys_refined = []\n",
    "for i in range(len(filtered_sig)):\n",
    "    temp_signal = filtered_sig[i][:-1]\n",
    "    temp_peaks, _ = signal.find_peaks(temp_signal, height = height_perc * avg_sign_amp[i], distance = distance_perc * avg_peak_dist[i])\n",
    "    temp_valleys, _ = signal.find_peaks(-temp_signal)\n",
    "    peaks_refined.append(temp_signal[temp_peaks])\n",
    "    peaks_refined.append(data_std['Abs Time'].values[temp_peaks])\n",
    "    valleys_refined.append(temp_signal[temp_valleys])\n",
    "    valleys_refined.append(data_std['Abs Time'].values[temp_valleys])\n",
    "\n",
    "fig, ax = plt.subplots(len(filtered_sig), 1, figsize=(18, 5 * N_PCA))\n",
    "for i in range(len(peaks_refined) // 2):    \n",
    "    ax[i].plot(data_std['Abs Time'], filtered_sig[i][:-1], label=\"Wavelet Filtered \"+PCA_LABELS[i])\n",
    "    ax[i].plot(peaks_refined[i * 2 + 1], peaks_refined[i * 2], 'x', label=\"Peaks\", markersize=10, markeredgewidth=3)\n",
    "    ax[i].axhline(avg_sign_amp[i] * height_perc, color='g', label=\"Peak Height Threshold\")\n",
    "    ax[i].legend(loc=\"best\")\n",
    "    ax[i].xaxis.set_major_locator(plt.MultipleLocator(5))\n",
    "    ax[i].set_xlabel(\"Time [s]\")\n",
    "    ax[i].set_ylabel(\"Magnitude\")\n",
    "    ax[i].legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Histogram and Estimate Respiratory Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After detecting the peaks, the sample of $T_i$ is generated, plotted in an histogram and fitted with a gaussian function in order to estimate the Respiration Rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dist = []\n",
    "for i in range(1, len(peaks_refined), 2):\n",
    "    temp_time_dist = []    \n",
    "    for j in range(1, len(peaks_refined[i])):\n",
    "        temp_peaks_time = peaks_refined[i]\n",
    "        temp_time_dist.append(temp_peaks_time[j]-temp_peaks_time[j-1])\n",
    "    time_dist.append(temp_time_dist)\n",
    "\n",
    "weights = [[var_ratios[i] for j in range(len(time_dist[i]))] for i in range(N_PCA)]\n",
    "\n",
    "time_dist_total = np.concatenate(time_dist)\n",
    "weights_total = np.concatenate(weights)\n",
    "print(f'The set of the T_i contains {len(time_dist_total)} samples.')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "bins = ax.hist(x=time_dist_total, bins=round(np.sqrt(len(time_dist_total))),label=\"Respiratory Period\",\n",
    "               weights=weights_total, facecolor=\"lightblue\", edgecolor=\"black\")\n",
    "\n",
    "bin_centers = (bins[1][:-1] + bins[1][1:]) / 2\n",
    "bin_counts = bins[0]\n",
    "bin_width = round(bins[1][1]-bins[1][0], 2)\n",
    "\n",
    "ax.set_xticks(bin_centers)\n",
    "ax.set_xticklabels(map(lambda x: round(x,1),bin_centers))\n",
    "\n",
    "def my_gaus(x, A, mu, sigma):\n",
    "    return A * np.exp(-0.5 * ((x-mu)/sigma) ** 2)\n",
    "\n",
    "params, params_cov = optimize.curve_fit(my_gaus, bin_centers, bin_counts, p0=[1, np.mean(time_dist_total), np.std(time_dist_total)], absolute_sigma=True, bounds=(0,[100, 100, 100]))\n",
    "fit_domain = np.sort(np.random.uniform(np.min(bin_centers), np.max(bin_centers), 1000))\n",
    "ax.plot(fit_domain, my_gaus(fit_domain, *params), label=\"Gaussian Fit\")\n",
    "ax.set_xlabel(\"Respiratory Period [s]\")\n",
    "ax.set_ylabel(f\"Counts / {bin_width} s\")\n",
    "errors = np.sqrt(bins[0])\n",
    "ax.errorbar(x=bin_centers, y=bins[0], yerr=errors/2, fmt='.', capsize=1, \n",
    "            color='dimgrey', elinewidth=2, label=\"1/2 $\\cdot$ Poisson Error\")\n",
    "\n",
    "ax.text(9.0, 2.9, f'$\\mu$ = ({params[1]:.1f} $\\pm$ {np.sqrt(np.diag(params_cov)[1]):.1f}) s \\n$\\sigma$ = ({params[2]:.1f} $\\pm$ {np.sqrt(np.diag(params_cov)[2]):.1f}) s', fontsize = 14)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "print('Fit parameters (Amplitude, Mean, Sigma):', params)\n",
    "print('Fit parameters errors (Amplitude, Mean, Sigma):', np.sqrt(np.diag(params_cov)))\n",
    "print(f'The estimated Respiratory Period is {params[1]:.2f} s, corresponding to a Respiratory Rate of {1 / params[1]:.2f} Hz, i.e. approximately {60 / params[1]:.1f} breaths per minute.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Respiratory Period estimate we choose the mean parameter returned by the gaussian fit, and we associate to it the respective error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respiratory Rate Variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we got an estimate of the Respiratory Rate, we need an appropriate quantity that measures its variability. As we have found [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8339683/), there are many quantities that are used to estimate Respiratory Rate Variability, according to the specific setup one is working on. A common RRV parameter used in the case of quantitative time series analysis is root mean square of successive differences (RMSSD), defined as \n",
    "$$\n",
    "\\text{RMSSD}(\\vec{x}) = \\sqrt{\\frac{1}{N}\\sum_{i=2}^{N}|x_i - x_{i-1}|^2}\n",
    "$$\n",
    "where the vector $\\vec{x}$ represents the set of $T_i$. However, to include in this calculation the information coming from the previous PCA, we decided to perform the weighted mean of the RMSSD of each selected PC, with the weights taken as the variability ratios of each PC. The equation becomes\n",
    "$$\n",
    "\\text{RMSSD}(\\vec{x}) = \\frac{1}{\\sum_{\\text{selected PCs}} w_{PC}} \\sum_{\\text{selected PCs}} \\sqrt{\\frac{1}{N_{PC}}\\sum_{i=2}^{N_{PC}} |x_i - x_{i-1}|^2} \\cdot w_{PC}\n",
    "$$\n",
    "Contrary to the previous case, fitting the histogram of the set of successive differences with a gaussian was inconclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RRVs_sq = np.zeros(shape=len(time_dist))\n",
    "for i, x in enumerate(time_dist):\n",
    "    x = np.array(x)\n",
    "    RRVs_sq[i] = np.sqrt(np.mean(np.diff(x) ** 2))\n",
    "\n",
    "RRV = np.average(RRVs_sq, weights=var_ratios[:N_PCA])\n",
    "print(f'The Respiratory Period Variability is {RRV:.2f} s.')\n",
    "\n",
    "RRVs_set = []\n",
    "for i, x in enumerate(time_dist):\n",
    "    x = np.array(x)\n",
    "    RRVs_set.append(np.abs(np.diff(x)))\n",
    "\n",
    "weights = [[var_ratios[i] for j in range(len(RRVs_set[i]))] for i in range(N_PCA)]\n",
    "weights_total = np.concatenate(weights)\n",
    "RRVs_set = np.concatenate(RRVs_set)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "bins = ax.hist(x=RRVs_set, bins=round(np.sqrt(len(RRVs_set))),label=\"Respiratory Period\",\n",
    "               weights=weights_total, facecolor=\"lightblue\", edgecolor=\"black\")\n",
    "\n",
    "bin_centers = (bins[1][:-1] + bins[1][1:]) / 2\n",
    "bin_counts = bins[0]\n",
    "bin_width = round(bins[1][1]-bins[1][0], 2)\n",
    "\n",
    "ax.set_xticks(bin_centers)\n",
    "ax.set_xticklabels(map(lambda x: round(x,1),bin_centers))\n",
    "\n",
    "fit_domain = np.sort(np.random.uniform(np.min(bin_centers), np.max(bin_centers), 1000))\n",
    "ax.set_xlabel(\"Respiratory Period Variability [s]\")\n",
    "ax.set_ylabel(f\"Counts / {bin_width} s\")\n",
    "errors = np.sqrt(bins[0])\n",
    "ax.errorbar(x=bin_centers, y=bins[0], yerr=errors/2, fmt='.', capsize=1, \n",
    "            color='dimgrey', elinewidth=2, label=\"1/2 $\\cdot$ Poisson Error\");\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Method without Filter\n",
    "\n",
    "When the filter fails we can devise an alternative method. We first consider only the frequencies range [0.1, 0.25] Hz and select the 3 frequencies with maximum power within it; we the compute their mean and then we get a final estimate with the weighted average of these values between all the considered Principal Components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (sample_freq > 0.1) & (sample_freq < 0.25)\n",
    "power_fft = np.abs(sig_fft)\n",
    "powers = power_fft[mask]\n",
    "frequencies = sample_freq[mask]\n",
    "\n",
    "list_freq=[]\n",
    "power_list=[]\n",
    "\n",
    "for j in range(N_PCA):\n",
    "    for i in range(3):\n",
    "        l=np.argmax(powers[:,j], axis=0)\n",
    "        list_freq.append(frequencies[l])\n",
    "        power_list.append(powers[l,j])\n",
    "        powers[l,j]=0\n",
    "        \n",
    "freq_ = np.array(list_freq)\n",
    "pow_ = np.array(power_list)\n",
    "pow_ = pow_/(pow_.sum())\n",
    "freq_ = freq_*pow_\n",
    "\n",
    "\n",
    "RR = np.array(freq_).sum()\n",
    "\n",
    "print(f\"Respiratory Rate Per Minute is: {RR * 60:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the features as a function of time individually, zooming in a restricted time window to highlight their trend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(Nvar, 2, figsize=(18, 4 * Nvar))\n",
    "for i in range(2):\n",
    "    for j in range(Nvar):\n",
    "        if i == 0:\n",
    "            x_range = raw_data[\"Abs Time\"]\n",
    "            data_range = raw_data[labels[j]]\n",
    "        else:\n",
    "            xmax, xmin = 16, 24\n",
    "            ixmin, ixmax = (xmax * ACQ_FREQ - 50,  xmin * ACQ_FREQ + 50)\n",
    "            data_range = raw_data.loc[ixmin:ixmax ,labels[j]]\n",
    "            x_range = raw_data.loc[ixmin:ixmax, \"Abs Time\"]\n",
    "            axs[j][i].set_xlim(xmax, xmin)\n",
    "\n",
    "        axs[j][i].plot(x_range, data_range, label=labels[j]) #c='b' ?\n",
    "        axs[j][i].set_xlabel(\"Time [s]\")\n",
    "\n",
    "        if \"Acc\" in labels[j]:\n",
    "            axs[j][i].set_ylabel(\"Linear Acceleration [mg]\")\n",
    "        elif \"Gyro\" in labels[j]:\n",
    "            axs[j][i].set_ylabel(\"Angular Velocity [deg/s]\")\n",
    "        elif \"Magn\" in labels[j]:\n",
    "            axs[j][i].set_ylabel(\"Magnetic Field [mG]\")\n",
    "\n",
    "        axs[j][i].legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Types of Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried different types of filters to find out which one worked best for our purposes.\n",
    "\n",
    "First, we implemente a simple Butterworth filter in the range [0.1, 0.4] Hz, which has the merit of not having any ripple in the passband (at the expense of rolling slowly towards zero in the stopband)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_RANGE = (0.1, 0.4)\n",
    "\n",
    "sos = signal.butter(4, FREQ_RANGE, 'bandpass', fs=ACQ_FREQ, output='sos')\n",
    "filtered_butter = signal.sosfilt(sos, data_pca[PCA_LABELS], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then try to better this result by constructing a filter pipeline, consisting of a wavelet filter, so as to keep time related information, followed by the previous Butterworth filter. In this case we adopt Daubechies 6 wavelets (db6), as they are smooth and their shape is similar to the shape of heartbeat and respiration pattern buried in SCG. Unfortunately, their maximum decomposition level is smaller than that of sym5 wavelets, so we cannot filter as precisely as above; we thus decompose up to level 8 and keep the respective approximation coefficients to reconstruct the time signal, therefore keeping frequencies in the [0, 0.39] Hz range. This method has the downside of keeping very low frequencies, but this problem is remedied by the following Butterworth filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter signal using wavelets\n",
    "lvl = 8\n",
    "if file_name != \"center_sternum.txt\":\n",
    "    lvl = 7\n",
    "    \n",
    "coeffs = pywt.wavedec(data_pca[PCA_LABELS], \"db6\", level=lvl, axis=0)\n",
    "\n",
    "#set coefficients related to undesired frequencies to zero \n",
    "for i in range(1, lvl + 1):\n",
    "    coeffs[i] = np.zeros_like(coeffs[i])\n",
    "\n",
    "#reconstruct time signal \n",
    "filtered_wt = pywt.waverec(coeffs, \"db6\", axis=0)\n",
    "\n",
    "#Apply Butterworth filter\n",
    "filtered_wtb = signal.sosfilt(sos, filtered_wt, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether all filters act as expected, let us plot as an example the power spectrum of the second principal component. In all three cases, the peaks around 0.2 Hz are kept while low and high frequencies are eliminated, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fft_wtb = fft.fftshift(fft.fft(filtered_wtb[:-1, :], axis=0))\n",
    "sig_fft_butter = fft.fftshift(fft.fft(filtered_butter, axis=0))\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.plot(sample_freq, np.abs(sig_fft[:, 1]), label=PCA_LABELS[1])\n",
    "plt.plot(sample_freq, np.abs(sig_fft_wt[:, 1]),\n",
    "             label=\"Wavelet Filtered \" + PCA_LABELS[1])\n",
    "plt.plot(sample_freq, np.abs(sig_fft_butter[:, 1]),\n",
    "             label=\"Wavelet Filtered \" + PCA_LABELS[1])\n",
    "plt.plot(sample_freq, np.abs(sig_fft_wtb[:, 1]),\n",
    "             label=\"Wavelet Filtered \" + PCA_LABELS[1])\n",
    "\n",
    "ax.set_xlim(0, 1.5)\n",
    "plt.xticks(np.arange(0, 1, 0.1))\n",
    "        \n",
    "plt.xlabel(\"Freq [Hz]\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us plot the reconstructed time signals using the filters just discussed and the one employed in the main analysis, in order to compare the reults; we also plot the original signal (rescaled by factor 2 for purely graphical reasons). \n",
    "\n",
    "We observe that the results for the simple Butterworth filter and those of the filter pipeline are almost identical, but both follow less closely the original signal compared to the wavelet sym5 filter. As the analysis is focused on the time related information, we conclude in the end that the latter filter is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot recostructed time signal\n",
    "fig, axs = plt.subplots(nrows=N_PCA, ncols=1, figsize=(18, N_PCA*5))\n",
    "\n",
    "for i in range(N_PCA):\n",
    "    axs[i].plot(data_pca[\"Abs Time\"], data_pca[PCA_LABELS[i]]/2, label=(\"Original \"+PCA_LABELS[i]))\n",
    "    axs[i].plot(data_pca[\"Abs Time\"], filtered_sig[i,:-1], label=(\"sym5 \"+PCA_LABELS[i]))\n",
    "    axs[i].plot(data_pca[\"Abs Time\"], filtered_butter[:, i], label=(\"Butterworth \"+PCA_LABELS[i]))\n",
    "    axs[i].plot(data_pca[\"Abs Time\"], filtered_wtb[:-1, i], label=(\"db6 + Butterworth \"+PCA_LABELS[i]))\n",
    "        \n",
    "    axs[i].set_xlabel(\"Time [s]\")\n",
    "    axs[i].set_ylabel(\"Magnitude\") # ???\n",
    "    axs[i].legend(loc=\"best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "facef925bc4600fb61034d39cee95b57bae21946036c03f370e6273d3ef2b545"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
